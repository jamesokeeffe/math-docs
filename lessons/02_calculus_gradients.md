# Step 2: Calculus & Gradients â€“ How Models Learn

## Overview

Calculus is the mathematical engine of machine learning. Every time a neural network adjusts its weights to improve performance, it's using calculusâ€”specifically, gradients and the chain rule. In this step, you'll understand the mathematical principles behind backpropagation and gradient descent.

## ğŸ¯ Learning Objectives

By the end of this step, you will:
- Master derivatives and partial derivatives conceptually and computationally
- Understand the chain rule as the foundation of backpropagation
- Compute gradients, Jacobians, and Hessians for optimization
- Implement gradient descent from scratch and visualize convergence
- Build a 2-layer neural network with manual forward and backward passes
- Train a neural network on MNIST using your own implementation

## ğŸ“š Mathematical Foundations

### Derivatives: Measuring Change

A derivative measures how a function changes as its input changes:
```
f'(x) = lim[hâ†’0] (f(x+h) - f(x)) / h
```

**Geometric Interpretation**: The slope of the tangent line at point x.

**Key Properties**:
- **Power rule**: d/dx[x^n] = nx^(n-1)
- **Product rule**: d/dx[f(x)g(x)] = f'(x)g(x) + f(x)g'(x)
- **Chain rule**: d/dx[f(g(x))] = f'(g(x)) Â· g'(x)

### Partial Derivatives: Multivariable Functions

For functions with multiple variables, partial derivatives measure change with respect to one variable while holding others constant:

```
âˆ‚f/âˆ‚x = lim[hâ†’0] (f(x+h, y) - f(x, y)) / h
```

**Example**: For f(x,y) = xÂ²y + 3xyÂ²
- âˆ‚f/âˆ‚x = 2xy + 3yÂ²
- âˆ‚f/âˆ‚y = xÂ² + 6xy

### The Gradient: Direction of Steepest Ascent

The gradient combines all partial derivatives into a vector:
```
âˆ‡f = [âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™]
```

**Key Properties**:
- **Direction**: Points toward steepest increase
- **Magnitude**: Rate of increase in that direction
- **Negative gradient**: Points toward steepest decrease (used in optimization)

### Chain Rule: The Heart of Backpropagation

For composite functions z = f(g(x)), the chain rule states:
```
dz/dx = dz/dg Â· dg/dx
```

**Multivariable chain rule** (crucial for neural networks):
If z = f(u, v) where u = g(x, y) and v = h(x, y), then:
```
âˆ‚z/âˆ‚x = âˆ‚z/âˆ‚u Â· âˆ‚u/âˆ‚x + âˆ‚z/âˆ‚v Â· âˆ‚v/âˆ‚x
```

### Gradient Descent: Following the Slope Downhill

Gradient descent is an optimization algorithm that finds function minima:
```
x_{t+1} = x_t - Î±âˆ‡f(x_t)
```

Where:
- **Î±**: Learning rate (step size)
- **âˆ‡f(x_t)**: Gradient at current point
- **Intuition**: Move in the direction opposite to the gradient

## ğŸ§  Neural Network Mathematics

### Forward Pass: Computing Outputs

For a 2-layer network:
```
Layer 1: zâ‚ = Wâ‚x + bâ‚
         aâ‚ = Ïƒ(zâ‚)
Layer 2: zâ‚‚ = Wâ‚‚aâ‚ + bâ‚‚
         aâ‚‚ = Ïƒ(zâ‚‚)
```

### Loss Function: Measuring Error

Mean Squared Error for regression:
```
L = (1/2n) Î£áµ¢ (yáµ¢ - Å·áµ¢)Â²
```

Cross-entropy for classification:
```
L = -Î£áµ¢ yáµ¢ log(Å·áµ¢)
```

### Backward Pass: Computing Gradients

Using the chain rule to compute gradients:

```
âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚ Â· âˆ‚zâ‚‚/âˆ‚Wâ‚‚
âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚aâ‚‚ Â· âˆ‚aâ‚‚/âˆ‚zâ‚‚ Â· âˆ‚zâ‚‚/âˆ‚aâ‚ Â· âˆ‚aâ‚/âˆ‚zâ‚ Â· âˆ‚zâ‚/âˆ‚Wâ‚
```

This is **backpropagation**: efficiently computing all gradients in one backward pass.

## ğŸ’» Coding Projects

### Project 1: Gradient Descent on Quadratic Function

**Mathematical Foundation**:
For f(x) = axÂ² + bx + c, the gradient is f'(x) = 2ax + b.
Gradient descent: x_{t+1} = x_t - Î±(2ax_t + b)

**Implementation**: [See code/02_gradient_descent.py](../code/02_gradient_descent.py)

### Project 2: 2-Layer Neural Network from Scratch

**Mathematical Steps**:
1. **Forward pass**: Compute activations layer by layer
2. **Loss computation**: Calculate error using loss function
3. **Backward pass**: Use chain rule to compute gradients
4. **Weight update**: Apply gradient descent to weights

**Implementation**: [See code/02_neural_network.py](../code/02_neural_network.py)

### Project 3: MNIST Training

**Application**: Train the neural network on handwritten digit recognition.

**Implementation**: [See code/02_mnist_training.py](../code/02_mnist_training.py)

## ğŸ”¬ Worked Examples

### Example 1: Computing Gradients by Hand

**Function**: f(x,y) = xÂ² + 2xy + yÂ²

**Gradients**:
- âˆ‚f/âˆ‚x = 2x + 2y
- âˆ‚f/âˆ‚y = 2x + 2y
- âˆ‡f = [2x + 2y, 2x + 2y]

**At point (1,2)**:
- âˆ‡f(1,2) = [2(1) + 2(2), 2(1) + 2(2)] = [6, 6]

### Example 2: Chain Rule in Action

**Composite function**: z = sin(xÂ² + yÂ²)

**Step-by-step**:
1. Let u = xÂ² + yÂ²
2. Then z = sin(u)
3. âˆ‚z/âˆ‚x = âˆ‚z/âˆ‚u Â· âˆ‚u/âˆ‚x = cos(u) Â· 2x = 2xÂ·cos(xÂ² + yÂ²)
4. âˆ‚z/âˆ‚y = âˆ‚z/âˆ‚u Â· âˆ‚u/âˆ‚y = cos(u) Â· 2y = 2yÂ·cos(xÂ² + yÂ²)

### Example 3: Backpropagation Through Simple Network

**Network**: x â†’ Wâ‚ â†’ Ïƒ â†’ Wâ‚‚ â†’ y
**Loss**: L = Â½(y - target)Â²

**Forward**:
- zâ‚ = Wâ‚x
- aâ‚ = Ïƒ(zâ‚)
- y = Wâ‚‚aâ‚

**Backward**:
- âˆ‚L/âˆ‚y = y - target
- âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚y Â· aâ‚ = (y - target) Â· aâ‚
- âˆ‚L/âˆ‚aâ‚ = âˆ‚L/âˆ‚y Â· Wâ‚‚ = (y - target) Â· Wâ‚‚
- âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚aâ‚ Â· Ïƒ'(zâ‚) Â· x = (y - target) Â· Wâ‚‚ Â· Ïƒ'(zâ‚) Â· x

## ğŸ§ª Practice Exercises

### Exercise 1: Derivative Computation
Compute derivatives for:
1. f(x) = 3xâ´ - 2xÂ³ + xÂ² - 5x + 1
2. g(x) = e^x sin(x)
3. h(x) = ln(xÂ² + 1)

### Exercise 2: Gradient Computation
For f(x,y) = xÂ³yÂ² + 2xy - yÂ³:
1. Find âˆ‚f/âˆ‚x and âˆ‚f/âˆ‚y
2. Compute âˆ‡f at point (1, -1)
3. Find critical points where âˆ‡f = 0

### Exercise 3: Chain Rule Practice
For z = e^(xÂ²+yÂ²) where x = tÂ² and y = tÂ³:
1. Find dz/dt using the chain rule
2. Evaluate at t = 1

**Solutions**: [See exercises/02_calculus_solutions.md](../exercises/02_calculus_solutions.md)

## ğŸ”— Connection to Machine Learning

### Why Gradients Matter

1. **Optimization**: Gradients point toward function minima/maxima
2. **Efficiency**: Backpropagation computes all gradients in O(n) time
3. **Generalization**: Same principles work for any differentiable function
4. **Scale**: Enables training networks with millions of parameters

### Common Activation Functions and Their Derivatives

```python
# Sigmoid
Ïƒ(x) = 1/(1 + e^(-x))
Ïƒ'(x) = Ïƒ(x)(1 - Ïƒ(x))

# ReLU
ReLU(x) = max(0, x)
ReLU'(x) = 1 if x > 0, else 0

# Tanh
tanh(x) = (e^x - e^(-x))/(e^x + e^(-x))
tanh'(x) = 1 - tanhÂ²(x)
```

### Gradient-Based Optimization Algorithms

1. **Vanilla Gradient Descent**: x â† x - Î±âˆ‡f(x)
2. **Momentum**: Accumulates gradients over time
3. **Adam**: Adaptive learning rates per parameter
4. **RMSprop**: Scales gradients by running average

## ğŸ“– Recommended Resources

### Essential Reading
- **3Blue1Brown Essence of Calculus** - Intuitive visual explanations
- **Mathematics for Machine Learning** (Deisenroth et al.) - Chapter 4

### Deep Dives
- **Deep Learning** (Goodfellow et al.) - Chapter 6 on optimization
- **Pattern Recognition and Machine Learning** (Bishop) - Mathematical foundations

## ğŸ¯ Key Takeaways

1. **Derivatives measure rates of change** - fundamental to optimization
2. **Chain rule enables efficient gradient computation** through complex networks
3. **Gradients point toward steepest ascent/descent** - basis of optimization
4. **Backpropagation is just chain rule applied systematically**
5. **Understanding calculus demystifies neural network training**

## â¡ï¸ Next Steps

Ready for [Step 3: Probability & Statistics](03_probability_statistics.md)? You'll learn how uncertainty and randomness are modeled in machine learning.

---

**ğŸš€ Interactive Learning**: Try the [Calculus & Gradients Jupyter Notebook](../notebooks/02_calculus_gradients.ipynb) for hands-on experimentation with gradient descent and backpropagation!